#!/usr/bin/env python3
"""status.json v1.0 â†’ v2.0 ç§»è¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""

import json
import shutil
from datetime import datetime
from pathlib import Path

import click

# ä¾å­˜ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from pdf_tools import generate_page_map
from extract_chapters import extract_chapters


def migrate_to_v2(project_root: Path) -> dict:
    """status.json ã‚’ v1.0 ã‹ã‚‰ v2.0 ã«ç§»è¡Œ"""
    status_path = project_root / "progress" / "status.json"
    raw_dir = project_root / "pdf" / "raw"
    output_dir = project_root / "pdf" / "output"

    # ç¾åœ¨ã®status.jsonã‚’èª­ã¿è¾¼ã¿
    with open(status_path, encoding="utf-8") as f:
        old_status = json.load(f)

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    backup_path = status_path.with_suffix(".json.bak")
    shutil.copy(status_path, backup_path)

    # æ–°ã—ã„ã‚¹ã‚­ãƒ¼ãƒã‚’æ§‹ç¯‰
    new_status = {
        "version": "2.0",
        "last_updated": datetime.now().isoformat(),
        "config": {
            "image_naming": "page_{:03d}.png",
            "dpi": 150,
            "spot_check_interval": 5,
            "max_retry": {
                "image_conversion": 3,
                "subagent_ocr": 2,
                "codex_review": 2
            }
        },
        "books": {}
    }

    # æ›¸ç±ã”ã¨ã«ç§»è¡Œ
    for book_name, old_book in old_status.get("books", {}).items():
        # ãƒšãƒ¼ã‚¸ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ç”Ÿæˆ
        try:
            page_map = generate_page_map(book_name, raw_dir)
        except Exception as e:
            page_map = {"files": [], "total_book_pages": 0}
            print(f"Warning: Could not generate page map for {book_name}: {e}")

        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ†é¡
        main_files = []
        supplement_files = []
        for f in page_map.get("files", []):
            if "åˆ¥å†Š" in f["file"]:
                supplement_files.append(f["file"])
            else:
                main_files.append(f["file"])

        # ç« æƒ…å ±ã‚’æŠ½å‡º
        chapters = []
        supplement_info = None
        toc_path = output_dir / book_name / "00_ç›®æ¬¡.md"

        if toc_path.exists():
            try:
                chapter_data = extract_chapters(toc_path)
                chapters = chapter_data.get("chapters", [])

                # åˆ¥å†Šæƒ…å ±
                if chapter_data.get("supplement"):
                    supplement_info = chapter_data["supplement"]
            except Exception as e:
                print(f"Warning: Could not extract chapters for {book_name}: {e}")

        # ç« ã«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±ã‚’è¿½åŠ 
        for i, ch in enumerate(chapters):
            ch["status"] = "pending"
            ch["output_file"] = None
            ch["review_status"] = None
            # ã‚¹ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯å¯¾è±¡: æœ€åˆã®ç« ã€5ã®å€æ•°
            ch_num = int(ch.get("number", "0").lstrip("0") or "0")
            ch["spot_check_required"] = (i == 0) or (ch_num > 0 and ch_num % 5 == 0)

        # ãƒšãƒ¼ã‚¸ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸ã‚’ä½œæˆ
        page_mapping = {}
        for f in page_map.get("files", []):
            page_mapping[f["file"]] = {
                "pdf_pages": f["pdf_pages"],
                "book_start": f["book_start"],
                "book_end": f["book_end"],
                "is_supplement": "åˆ¥å†Š" in f["file"]
            }

        # æ–°æ›¸ç±ãƒ‡ãƒ¼ã‚¿
        new_book = {
            "status": old_book.get("status", "not_started"),
            "files": {
                "main": main_files,
                "supplement": supplement_files
            },
            "page_mapping": page_mapping,
            "total_pages": page_map.get("total_book_pages", 0),
            "toc_pages": old_book.get("toc_pages"),
            "chapters": chapters,
            "completed_chapters": old_book.get("completed_chapters", 0),
            "total_chapters": len(chapters),
            "notes": old_book.get("notes", "")
        }

        # åˆ¥å†ŠãŒã‚ã‚‹å ´åˆ
        if supplement_files and supplement_info:
            new_book["supplement"] = {
                "file": supplement_files[0] if supplement_files else None,
                "title": supplement_info.get("title", ""),
                "status": "not_started",
                "chapters": supplement_info.get("chapters", [])
            }

        new_status["books"][book_name] = new_book

    return new_status


@click.command()
@click.option("--dry-run", is_flag=True, help="å®Ÿè¡Œã›ãšã«çµæœã‚’è¡¨ç¤º")
@click.option("--output", "-o", type=click.Path(), help="å‡ºåŠ›å…ˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä¸Šæ›¸ãï¼‰")
def main(dry_run, output):
    """status.json ã‚’ v2.0 ã«ç§»è¡Œ"""
    project_root = Path(__file__).parent.parent
    status_path = project_root / "progress" / "status.json"

    click.echo("status.json v1.0 â†’ v2.0 ç§»è¡Œã‚’é–‹å§‹...")

    new_status = migrate_to_v2(project_root)

    if dry_run:
        click.echo("\n[Dry Run] ä»¥ä¸‹ã®å†…å®¹ã§æ›´æ–°ã•ã‚Œã¾ã™:\n")
        click.echo(json.dumps(new_status, indent=2, ensure_ascii=False)[:2000])
        click.echo("\n... (truncated)")
    else:
        output_path = Path(output) if output else status_path
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(new_status, f, indent=2, ensure_ascii=False)
        click.echo(f"\nâœ… ç§»è¡Œå®Œäº†: {output_path}")
        click.echo(f"   ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {status_path.with_suffix('.json.bak')}")

        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        click.echo("\nğŸ“Š ã‚µãƒãƒªãƒ¼:")
        for book_name, book in new_status["books"].items():
            click.echo(f"   {book_name}: {book['total_chapters']}ç« , {book['total_pages']}ãƒšãƒ¼ã‚¸")


if __name__ == "__main__":
    main()
